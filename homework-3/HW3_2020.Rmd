---
title: ANLYTC3 Homework 3
author: Julian Terry S. Bass
output: html_document
---

#### Instructions 

The due date is 09:30AM on Feb 23 (Tue). Submit BOTH the Knit HTML file and the Rmd file.

Code should be clearly commented. Plots should be presentable and properly labeled/titled. Mitigate overplotting whenever possible. 

You may hard code whatever written answers are required.

#### Preliminaries

Here are some libraries that you may need.
```{r}
library(ggplot2)
library(plyr)
library(reshape2)
library(knitr)
library(binom) 
```

We will use the data files `county_data.csv` and `county_ggplot.rda`, which were part of the lecture materials. We'll assume they are in the same directory as this .Rmd file.

```{r}
county.data = read.csv(file = 'county_data.csv', header=TRUE)
load('county_ggplot.rda')
```


#### Questions 

**Problem 1:** 

Make a scatterplot of the per capita violent crime rates for each county as function of the population. Remember to mitigate overplotting. Does this plot resemble those for deaths, births, or infant deaths that we saw in the notes? If not, what is the biggest difference?

Note: you may want to use a log transform on the x-axis to see the data more clearly.

```{r fig.width=6, fig.height=4, dpi=80, fig.align='center'}
# fill in

# Scatterplot function that takes in a per capita column value, a function (in this case population) and a plot title
per.capita.scatterplot = function(x, n, main.title) {
  CI.data = with(county.data, binom.confint(x = x, n = n, methods = 'exact'))

  county.augment = with(CI.data, 
      mutate(county.data, 
      lower.CI = lower, upper.CI = upper, per.capita = mean))

  kable( arrange(county.augment, desc(x))[, c("name", "population", "violent.crimes", "per.capita", "lower.CI")], digits=4)

  ggplot(county.augment, aes(x=n, y=per.capita)) + geom_point() + geom_smooth() + ggtitle(main.title) +  scale_x_log10()
  
}

# Violent Crimes by Population
per.capita.scatterplot(county.data$violent.crimes, county.data$population, "Violent Crimes by Population")

# Births by Population
per.capita.scatterplot(county.data$births, county.data$population, "Births by Population")

# Deaths by Population
per.capita.scatterplot(county.data$deaths, county.data$population, "Deaths by Population")

# Infant Deaths by Population
per.capita.scatterplot(county.data$infant.deaths, county.data$population, "Infant Deaths by Population")


```

ANS: I'll admit that the results from above don't seem to logically fit each other. Despite seeing an increase in violent crimes with greater populations, we see a decrease in deaths. You'd think more deaths would come up in this case.

Birth data seems a bit more promising in that with higher populations with more births, we see the rate of infant deaths stagnate and level out with a general decrease. This means that while more babies are born in higher populations, infant death rates go down.

**Problem 2:**

Create a function called `find.std.residual()`, which lets you specify a column in the `county.data` data frame, and then uses the p-value approach to identify counties where people may potentially be at higher risk. 

Specifically, your function should take the following inputs

* the `county.data` data set
* `variable`: the name of the column that you want to inspect
* `null.prob`: this variable determines the null hypothesis that you will compare all counties to. Specifically, the null is that all counties are `binomial(population, null.prob)` random variables.

Your function should return a data frame with all of the columns in `county.data`, plus the following additional columns

* `expected.null`: the expected number of outcomes under the null hypothesis for each county
* `variance.null`: the variance under the null hypothesis for each county
* `residual`: the difference between the observed count and that predicted under the null
* `std.residual`: the standardized residual

The rows of the data frame should be sorted in decreasing order by `std.residual`

Be sure to comment your function thoroughly so that it is easy to understand later.

```{r fig.width=8, fig.height=6, dpi=100, fig.align='center'}
# fill in

find.std.residual = function(data, variable, null.prob) {
  
  data = mutate(data, expected.null = variable * null.prob,
                std.dev.null = sqrt(expected.null * (1 - null.prob)),
                residual = variable - expected.null,
                std.residual = residual / std.dev.null)
  
  # Decreasing order data by std.residual
  #ordered = data[order(-data$std.residual), ]
  return(data.frame(arrange(data, desc(std.residual))))
}


```

**Problem 3:**

Use your function from problem 2 to create a table showing the top fifteen counties for `violent.crimes`, under a null hypothesis that each county has a crime per capita rate of 1%.

```{r fig.width=8, fig.height=6, dpi=100, fig.align='center'}
# fill in

# Initial function call
top.15.crimes = find.std.residual(county.data, county.data$violent.crimes, 0.01)[1:15, ]

# Retrieving only the top 15 records in decreasing crime rate order
#top.15.crimes = top.15.crimes[order(-top.15.crimes$violent.crimes)[1:15], ]
kable(top.15.crimes, digits = 4)
top.15.crimes

```

**Problem 4:**

Create a function `map.std.residual()` which takes the output of your function `find.std.residual()`, and creates a choropleth plot.

The inputs to the function should be

* `county.gg`: the data frame needed to draw the map
* `county.data`: the output from `find.std.residual()`

The output should be a map that can be printed, to which you can customize later by adding calls like `scale_fill_gradient2()` and `labs()`

Use this function to create a choropleth plot of the results from problem 3.

```{r fig.width=10, fig.height=6, dpi=100, fig.align='center'}
# fill in


# Code taken from Exercise 6 solution
# Creation of the map.std.residual function with 2 parameters which are county.gg, county.data
map.std.residual = function(county.gg, county.data) {
  # Getting the US.per.capita by dividing the sum of violent.crimes to population
  US.per.capita = sum(county.data$violent.crimes) / sum(county.data$population)
  # Merging of the 2 data frames by the columns fips and STCOU
  county.merge = merge(x = county.gg, y = county.data, by.x = "fips", by.y = "STCOU")
  # Arranging the data frame county.merge according to order number
  county.merge = arrange(county.merge, order)
  #starting of data map_data
  county_list = map_data("county")
  
  # ggplot automatically return value of the map.std.residual function that creates the map
ggplot() + geom_map(data = county_list, map = county_list, mapping = aes(x = long, y = lat, map_id = region), col = "white", fill = "grey") + geom_polygon(data = county.merge, mapping = aes(x = long, y = lat, group = group, fill = std.residual)) + coord_map() + labs(x = "Longitude", y = "Latitude", fill = "Standard Residual", group = "Counties", title = "Top 15 Counties \n with High Standard Residual") + scale_fill_gradientn(limits = c(0,4000), colours=c("grey", "violet", "blue"), breaks=c(0, 1000 , 2000, 3000, 4000)
)
}

# Running the function with the appropriate data sets and adding some styles to the created map
map.std.residual(county.gg, top.15.crimes) 

```

**Problem 5:**

Using the functions you wrote, make a new choropleth plot and table, this time using the US violent crime per capita rate as your null hypothesis. 

```{r fig.width=10, fig.height=6, dpi=100, fig.align='center'}
# fill in

# Getting the Violent Crime per Capita Rate
crime.rate.per.capita = sum(county.data$violent.crimes) / sum(county.data$population)

#US.crime.per.capita = data.frame(find.std.residual(county.data, county.data$violent.crimes, crime.rate.per.capita))

# Passing the crime rate as the null hypothesis
map.std.residual(county.gg, find.std.residual(county.data, county.data$violent.crimes,  crime.rate.per.capita)[1:15,])

```

Comment on why the map and table from problem 5 are different from those of problems 4 and 3.

I think it simply has to do with the number of records in this case. Since the main data set has the full set of counties with their many geo-plotted data points, R is able to constitute a full map view of these locations, but when we limit those records to only 15 (in this case those with the top crime rates), there's less geographical information to make a full map which is why it appears incomplete.

Interestingly, despite the map of the top 15 countries being incomplete, you can still make out how the deeply-colored sections still match with the map of the main data set.


